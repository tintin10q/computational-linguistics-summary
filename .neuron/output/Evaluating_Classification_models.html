<!DOCTYPE html><html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type" /><meta content="width=device-width, initial-scale=1" name="viewport" /><!--replace-start-0--><!--replace-start-5--><!--replace-start-8--><title>Evaluating Classification Models - Neuron Zettelkasten</title><!--replace-end-8--><!--replace-end-5--><!--replace-end-0--><link href="https://cdn.jsdelivr.net/npm/fomantic-ui@2.8.7/dist/semantic.min.css" rel="stylesheet" /><link href="https://fonts.googleapis.com/css?family=Merriweather|Libre+Franklin|Roboto+Mono&amp;display=swap" rel="stylesheet" /><!--replace-start-1--><!--replace-start-4--><!--replace-start-7--><link href="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" rel="icon" /><meta content="After you have made your Classification/Classification system how do you evalutate it against other options?" name="description" /><link href="https://neuron.zettel.page/Evaluating_Classification_models.html" rel="canonical" /><meta content="Evaluating Classification Models" property="og:title" /><meta content="Neuron Zettelkasten" property="og:site_name" /><meta content="article" property="og:type" /><meta content="Evaluating Classification models" property="neuron:zettel-id" /><meta content="Evaluating_Classification_models" property="neuron:zettel-slug" /><meta content="root/Classification" property="neuron:zettel-tag" /><script type="application/ld+json">[{"@context":"https://schema.org","itemListElement":[{"name":"Clasification","item":"https://neuron.zettel.page/Classification.html","@type":"ListItem","position":1}],"@type":"BreadcrumbList"}]</script><style type="text/css">body{background-color:#eeeeee !important;font-family:"Libre Franklin", serif !important}body .ui.container{font-family:"Libre Franklin", serif !important}body h1, h2, h3, h4, h5, h6, .ui.header, .headerFont{font-family:"Merriweather", sans-serif !important}body code, pre, tt, .monoFont{font-family:"Roboto Mono","SFMono-Regular","Menlo","Monaco","Consolas","Liberation Mono","Courier New", monospace !important}body div.z-index p.info{color:#808080}body div.z-index ul{list-style-type:square;padding-left:1.5em}body div.z-index .uplinks{margin-left:0.29999em}body .zettel-content h1#title-h1{background-color:rgba(33,133,208,0.1)}body nav.bottomPane{background-color:rgba(33,133,208,2.0e-2)}body div#footnotes{border-top-color:#2185d0}body p{line-height:150%}body img{max-width:100%}body .deemphasized{font-size:0.94999em}body .deemphasized:hover{opacity:1}body .deemphasized:not(:hover){opacity:0.69999}body .deemphasized:not(:hover) a{color:#808080 !important}body div.container.universe{padding-top:1em}body div.zettel-view ul{padding-left:1.5em;list-style-type:square}body div.zettel-view .pandoc .highlight{background-color:#ffff00}body div.zettel-view .pandoc .ui.disabled.fitted.checkbox{margin-right:0.29999em;vertical-align:middle}body div.zettel-view .zettel-content .metadata{margin-top:1em}body div.zettel-view .zettel-content .metadata div.date{text-align:center;color:#808080}body div.zettel-view .zettel-content h1{padding-top:0.2em;padding-bottom:0.2em;text-align:center}body div.zettel-view .zettel-content h2{border-bottom:solid 1px #4682b4;margin-bottom:0.5em}body div.zettel-view .zettel-content h3{margin:0px 0px 0.4em 0px}body div.zettel-view .zettel-content h4{opacity:0.8}body div.zettel-view .zettel-content div#footnotes{margin-top:4em;border-top-style:groove;border-top-width:2px;font-size:0.9em}body div.zettel-view .zettel-content div#footnotes ol > li > p:only-of-type{display:inline;margin-right:0.5em}body div.zettel-view .zettel-content aside.footnote-inline{width:30%;padding-left:15px;margin-left:15px;float:right;background-color:#d3d3d3}body div.zettel-view .zettel-content .overflows{overflow:auto}body div.zettel-view .zettel-content code{margin:auto auto auto auto;font-size:100%}body div.zettel-view .zettel-content p code, li code, ol code{padding:0.2em 0.2em 0.2em 0.2em;background-color:#f5f2f0}body div.zettel-view .zettel-content pre{overflow:auto}body div.zettel-view .zettel-content dl dt{font-weight:bold}body div.zettel-view .zettel-content blockquote{background-color:#f9f9f9;border-left:solid 10px #cccccc;margin:1.5em 0px 1.5em 0px;padding:0.5em 10px 0.5em 10px}body div.zettel-view .zettel-content.raw{background-color:#dddddd}body .ui.label.zettel-tag{color:#000000}body .ui.label.zettel-tag a{color:#000000}body nav.bottomPane ul.backlinks > li{padding-bottom:0.4em;list-style-type:disc}body nav.bottomPane ul.context-list > li{list-style-type:lower-roman}body .footer-version img{-webkit-filter:grayscale(100%);-moz-filter:grayscale(100%);-ms-filter:grayscale(100%);-o-filter:grayscale(100%);filter:grayscale(100%)}body .footer-version img:hover{-webkit-filter:grayscale(0%);-moz-filter:grayscale(0%);-ms-filter:grayscale(0%);-o-filter:grayscale(0%);filter:grayscale(0%)}body .footer-version, .footer-version a, .footer-version a:visited{color:#808080}body .footer-version a{font-weight:bold}body .footer-version{margin-top:1em !important;font-size:0.69999em}@media only screen and (max-width: 768px){body div#zettel-container{margin-left:0.4em !important;margin-right:0.4em !important}}body span.zettel-link-container span.zettel-link a{color:#2185d0;font-weight:bold;text-decoration:none}body span.zettel-link-container span.zettel-link a:hover{background-color:rgba(33,133,208,0.1)}body span.zettel-link-container span.extra{color:auto}body span.zettel-link-container.errors{border:solid 1px #ff0000}body span.zettel-link-container.errors span.zettel-link a:hover{text-decoration:none !important;cursor:not-allowed}body [data-tooltip]:after{font-size:0.69999em}body div.tag-tree div.node{font-weight:bold}body div.tag-tree div.node a.inactive{color:#555555}body .tree.flipped{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}body .tree{overflow:auto}body .tree ul.root{padding-top:0px;margin-top:0px}body .tree ul{position:relative;padding:1em 0px 0px 0px;white-space:nowrap;margin:0px auto 0px auto;text-align:center}body .tree ul::after{content:"";display:table;clear:both}body .tree ul:last-child{padding-bottom:0.1em}body .tree li{display:inline-block;vertical-align:top;text-align:center;list-style-type:none;position:relative;padding:1em 0.5em 0em 0.5em}body .tree li::before{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{right:auto;left:50%;border-left:solid 2px #cccccc}body .tree li:only-child{padding-top:0em}body .tree li:only-child::after{display:none}body .tree li:only-child::before{display:none}body .tree li:first-child::before{border-style:none;border-width:0px}body .tree li:first-child::after{border-radius:5px 0px 0px 0px}body .tree li:last-child::after{border-style:none;border-width:0px}body .tree li:last-child::before{border-right:solid 2px #cccccc;border-radius:0px 5px 0px 0px}body .tree ul ul::before{content:"";position:absolute;top:0px;left:50%;border-left:solid 2px #cccccc;width:0px;height:1.19999em}body .tree li div.forest-link{border:solid 2px #cccccc;padding:0.2em 0.29999em 0.2em 0.29999em;text-decoration:none;display:inline-block;border-radius:5px 5px 5px 5px;color:#333333;position:relative;top:2px}body .tree.flipped li div.forest-link{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}</style><script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css" rel="stylesheet" /><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/plugins/autoloader/prism-autoloader.min.js"></script><!--replace-end-7--><!--replace-end-4--><!--replace-end-1--></head><body><div class="ui fluid container universe"><!--replace-start-2--><!--replace-start-3--><!--replace-start-6--><nav class="flipped tree deemphasized" id="zettel-uptree" style="transform-origin: 50%"><ul class="root"><li><ul><li><div class="forest-link"><span class="zettel-link-container"><span class="zettel-link"><a href="Classification.html">Clasification</a></span></span></div></li></ul></li></ul></nav><div class="ui text container" id="zettel-container" style="position: relative"><div class="zettel-view"><article class="ui raised attached segment zettel-content"><div class="pandoc"><h1 id="title-h1">Evaluating Classification Models</h1><p>After you have made your <a href="Classification/Classification" title="cf">Classification/Classification</a> system how do you evalutate it against other options?</p><h2 id="intrinsic-evauation">Intrinsic Evauation</h2><p>Define a metric and check wich system does best.</p><h2 id="extrinsic-evaluation">Extrinsic Evaluation</h2><p>Embed a tool in a larger system and check how much perormance on a downstream task improves given the output of two different versions of your tool. So you have the clasifier, but you see how much the performance on something the classifier would be used for improves.</p><h2 id="example">Example</h2><p>Lets say spam detection.</p><ul><li>Intrinsic evaluation would be we have a bag of spam emails and normal emails. Then we could say the clasifier was correct 95% of the times and incorrect 5% of the times.</li><li>Extrinsic evaluation would be like we got 66% decrease in people that got scammed that used our tool.</li></ul><p>So extrinsic is not the tool itself you evaluate, but you see in how the tool helps to achieve a goal it was made for and if it helps at all.</p><hr /><p>We would like a spam filter to be perfect, but this is not going to happen. Either you classify emails as spam when it’s not spam, or you miss emails as spam when its is spam. You have to choose which one is worse for your application.</p><h1 id="intrinsic-evaluation-methods">Intrinsic evaluation methods</h1><p>Whenever you get results from your model you get:</p><ul><li>True positives (TP): Correctly classified that it was this class.</li><li>True negatives (TN): Correctly classified that it was not this class.</li><li>False positives (FP): Incorreclty classified that it was this class.</li><li>False negatives (FN): Incorreclty classified that it was not this class.</li></ul><p>From these we can come up with intrinsic evaluations.</p><p>!<a href="images/Pasted image 20220216130019.webp" title="cf">images/Pasted image 20220216130019.webp</a></p><h2 id="acuracy">Acuracy</h2><p>Acuracy is the number of correclty classified points. Simple.</p><h2 id="precision">Precision</h2><p>The first one is precision. The idea of this is that you devide the true positives by all the data points that where classified as this class. So this means: <span class="math display">$$Precision = \frac{TP}{TP+FP}$$</span></p><p>This can be seen as a percentage of all points that were classied as this class that was correct. So precision really punishes false positives. It doesn’t matter if you missed some true positives as long as you don’t have a lot of false positives.</p><p>To use this measure you need to classify atleast one true positive otherwise you try to devide 0 and then the score is 0.</p><h2 id="recall">Recall</h2><p>Recall is the proportion of correctly classified data points out of the data points which belonged to that class.</p><p><span class="math display">$$Recall = \frac{TP}{TP+FN}$$</span></p><p>You can see recall of the number of correctly classified spam emails out of the emails that should have been classified as spam. You don’t care about the mistakes but you care about that you catch everything you have to catch.</p><p>With recall, it doesn’t matter how often you wrongly guessed as long as you got all data points which belonged to the class (the true positives). So this punishes false negatives. I think false negatives are the worst.</p><h2 id="f-measure">F-Measure</h2><p>F-Measure combines precision and recall into a new shiny formula. F-Measure is described as the harmonic mean between precision and recall. The harmonic mean is more conservative than the arithmetic mean.</p><p>This is the formula:</p><p><span class="math display">$$F~Measure = \frac{(\beta^{2} + 1) \cdot Precision \cdot Recall}{\beta^{2}  \cdot Precision \cdot Recall}$$</span></p><p>The idea of the <span class="math inline">\(\beta\)</span> is a weight that you can use to make either precision or recall more important. If you do <span class="math inline">\(\beta \gt 1\)</span> you make recall more important and <span class="math inline">\(\beta \lt 1\)</span> than you make precision more important.</p><p>Often you don’t make one more significant than the other, and you just set <span class="math inline">\(\beta = 1\)</span>. When you do this you call the F-Measure score the <strong>F1 score</strong>. Setting <span class="math inline">\(\beta\)</span> is mostly based on domain knolege. If you don’t have it then just set it to 1.</p><h3 id="macro-averaging">Macro averaging</h3><p>When there are more than two classes, we compute the F-measure for all classes seperatly and then average them assigning equal importance. <strong>This is usefull when good performance is necessary in all the classes</strong>, regardless of the requency in which they appear. Because if you do it like this one class that has bad performance will decrease the averaged F1 score a lot.</p><h3 id="micro-averaging">Micro averaging</h3><p>With micro averaging you collect all the decisions for all the classes in a single <a href="Classification/contingency table" title="cf">Classification/contingency table</a> and then compute precision and recall from that table. This is usefull when good performance is more imporatnt for the most frequent classes.</p><h2 id="statisical-test">Statisical test</h2><p>You can often not use statistical test like t-test because often classification samples are not normally distrobuted.</p><h2 id="bootstrapping">Bootstrapping</h2><p>Bootstrapping is when you artificially increase the number of test sets by drawing a lot of samples from a given test set with replacement (use multiple times), perform your task, record the score, factor the performance of the whole test set, then simply check the percentage of runs in which a system beats the other. This is not super important.</p><p>So you pick samples of data points of the whole test set and then run multiple times. You can then see if one system is more better then the other on many samples.</p></div></article><nav class="ui attached segment deemphasized backlinksPane" id="neuron-backlinks-pane"><h3 class="ui header"><span title="Backlinks from folgezettel parents">Uplinks</span></h3><ul class="backlinks"><li><span class="zettel-link-container folge"><span class="zettel-link"><a href="Classification.html">Clasification</a><span data-nosnippet="" style="user-select: none; color: gray" title="Folgezettel">#</span></span></span><ul class="context-list" style="zoom: 85%;"><li class="item"><div class="pandoc"><em>Parent directory zettel</em></div></li></ul></li></ul></nav><nav class="ui attached segment deemphasized bottomPane" id="neuron-tags-pane"><div><span class="ui basic label zettel-tag" title="Tag">root/Classification</span></div></nav><nav class="ui bottom attached icon compact inverted menu blue" id="neuron-nav-bar"><!--replace-start-9--><!--replace-end-9--><a class="item" href="https://github.com/srid/neuron/edit/master/doc/./Classification/Evaluating Classification models.md" title="Edit this page"><i class="edit icon"></i></a><a class="right item" href="impulse.html" title="Open Impulse"><i class="wave square icon"></i></a></nav></div></div><!--replace-end-6--><!--replace-end-3--><!--replace-end-2--><div class="ui center aligned container footer-version"><div class="ui tiny image"><a href="https://neuron.zettel.page"><img alt="logo" src="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" title="Generated by Neuron 1.9.35.3" /></a></div></div></div></body></html>